{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import bisc.immport_templates as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JIRA BDD-2098  \n",
    "**Goal:**  \n",
    "    1. replace user def subjects by accessions in data matrix  \n",
    "    2. figure out how to parse data matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DIRECTORY CELL\n",
    "beg = 'Please enter file path for '\n",
    "subject_dir = input(beg + 'subject files: \\n')\n",
    "omrf_all = input(beg + \"Please enter\" omrf_all (all participatns omrf) filepath: \\n\")\n",
    "omrf_all = input(beg + \"ginger cohorot omrf filepath: \\n\")\n",
    "planned_visits = input(beg + \"planned visits filepath: \\n\")\n",
    "\n",
    "#curration stuff\n",
    "template_dir = input(beg + 'project templates: \\n')\n",
    "#subject_dir = \n",
    "workingfile = input(beg + 'all_participant OMRF deidentification: \\n')\n",
    "hai_data = input(beg + 'HAI_rawdata: \\n')\n",
    "inter_data = input(beg + 'interventions rawdata: \\n')\n",
    "assessments = input(beg+ 'assessments rawdata: \\n')\n",
    "wb_path = input(beg + ' ')\n",
    "wb_data = input(beg + 'WB rawdata: \\n')\n",
    "elispot_data = input(beg + 'EliSPOT data: \\n')             \n",
    "elisa_data1 = input(beg + 'ELISA raw data: \\n')\n",
    "elisapath = input(beg + 'desired ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "#subject_dir = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/subjects/OMRF_subjects.txt\"\n",
    "\n",
    "subjects = {}\n",
    "sub_sdy = {\"1\":\"SDY196\",\n",
    "           \"2\":\"SDY197\",\n",
    "           \"3\":\"SDY198\",\n",
    "           \"4\":\"SDY199\",\n",
    "           \"5\":\"SDY200\",\n",
    "           \"6\":\"SDY201\",\n",
    "}\n",
    "\n",
    "with open(subject_dir, \"r\") as sbj:\n",
    "    sbjfl = sbj.readline()\n",
    "    for sbjlines in sbj:\n",
    "        sbjlines = sbjlines.strip(\"\\n\")\n",
    "        sbjstuff = sbjlines.split(\"\\t\")\n",
    "        \n",
    "        subjects[sbjstuff[3]] = sbjstuff[4]\n",
    "\n",
    "print(len(set(subjects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "#omrf_all = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/all_participants_OMRF.txt\"\n",
    "#omrf_ginger = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/gingers_cohort_OMRF.txt\"\n",
    "\n",
    "dfall = pd.read_table(omrf_all)\n",
    "print(len(set(dfall.Barcode)))\n",
    "dfg = pd.read_table(omrf_ginger)\n",
    "print(len(set(dfg.Barcode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## planned visits\n",
    "#planned_visits = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/planned_visits/OMRF_Planned_Visits.txt\"\n",
    "pv_firstday = {}    ## all the same visit days range\n",
    "\n",
    "with open(planned_visits, \"r\") as pv:\n",
    "    pvfl = pv.readline()\n",
    "    for pvl in pv:\n",
    "        pvstf = pvl.split(\"\\t\")\n",
    "        pv_firstday[pvstf[1]] = pvstf[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [omrf_all, omrf_ginger]\n",
    "day0 = defaultdict(dict)\n",
    "for fl in files:\n",
    "    ## Create new output file:\n",
    "    tmp0 = fl.split(\".\")\n",
    "    newfilename = \"\".join([tmp0[0], \"_deidentified\", tmp0[1]])\n",
    "    with open(fl, \"r\") as omrf, open(newfilename, \"w\") as nwomrf:\n",
    "        headers = omrf.readline()\n",
    "        nwomrf.write(\"SDY_ACC\\t\" + headers)\n",
    "        \n",
    "        index_drawdates = []\n",
    "        hdr = headers.split(\"\\t\")\n",
    "        visit_count = defaultdict(dict)\n",
    "\n",
    "        for hd in hdr:\n",
    "            if hd.startswith(\"draw_\"):\n",
    "                index_drawdates.append(hdr.index(hd))\n",
    "\n",
    "        for omrflines in omrf:\n",
    "            omrfdata = omrflines.split(\"\\t\")\n",
    "            tmp1 = subjects[omrfdata[0]]\n",
    "            year = omrfdata[1]\n",
    "\n",
    "            visit_count[omrfdata[0]][omrfdata[1]] = 0\n",
    "            vc = 0\n",
    "\n",
    "            for i in range(1, len(omrfdata)):\n",
    "                data = omrfdata[i]\n",
    "                data = data.strip()\n",
    "                \n",
    "                if i in index_drawdates:\n",
    "                    visit_count[omrfdata[0]][omrfdata[1]] +=1\n",
    "                    if re.match(\"\\d\\d\\/\\d\\d\\/\\d\\d\\d\\d\", data):\n",
    "                        if omrfdata[0] in day0:\n",
    "                            if omrfdata[1] in day0[omrfdata[0]]:\n",
    "                                mh0, dy0, yr0 = day0[omrfdata[0]][omrfdata[1]].split(r\"/\")\n",
    "                                mh, dy, yr = data.split(r\"/\")\n",
    "                                newdate = date(int(yr), int(mh), int(dy)) - date(int(yr0), int(mh0), int(dy0))\n",
    "                                omrfdata[omrfdata.index(data)] = str(newdate.days + int(omrfdata[vc]))\n",
    "\n",
    "                            else:\n",
    "                                day0[omrfdata[0]][omrfdata[1]] = data\n",
    "                                vc = int(omrfdata.index(data))\n",
    "                                if visit_count[omrfdata[0]][omrfdata[1]] == 1:\n",
    "                                    omrfdata[omrfdata.index(data)] = \"0\"\n",
    "                                else:\n",
    "                                    omrfdata[omrfdata.index(data)] = pv_firstday[str(visit_count[omrfdata[0]][omrfdata[1]])]\n",
    "                        else:\n",
    "                            day0[omrfdata[0]][omrfdata[1]] = data\n",
    "                            vc = int(omrfdata.index(data))\n",
    "                            if visit_count[omrfdata[0]][omrfdata[1]] == 1:\n",
    "                                omrfdata[omrfdata.index(data)] = \"0\"\n",
    "                            else:\n",
    "                                omrfdata[omrfdata.index(data)] = pv_firstday[str(visit_count[omrfdata[0]][omrfdata[1]])]\n",
    "\n",
    "            omrfdata[0] = tmp1\n",
    "            omrfdata.insert(0, sub_sdy[year])            \n",
    "            nwomrf.write(\"\\t\".join(omrfdata))\n",
    "            \n",
    "### FIX SUBSEQUENT INSTANCES OF SUBJECTS TO GET THE DAY 0\n",
    "### FIX THE CASES WHERE DAY0 is not the first day - use planned visits maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURATION STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template_dir = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/templates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_dir = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/subjects/OMRF_subjects.txt\"\n",
    "\n",
    "sub_acc = {}\n",
    "sdy_yr = {\n",
    "    \"SDY196\" : \"1\",\n",
    "    \"SDY197\" : \"2\",\n",
    "    \"SDY198\" : \"3\",\n",
    "    \"SDY199\" : \"4\",\n",
    "    \"SDY200\" : \"5\",\n",
    "    \"SDY201\" : \"6\"\n",
    "}\n",
    "\n",
    "with open(subject_dir, \"r\") as sb:\n",
    "    sbfl = sb.readline()\n",
    "    for sblines in sb:\n",
    "        sblines = sblines.strip(\"\\n\")\n",
    "        sbstuff = sblines.split(\"\\t\")\n",
    "        \n",
    "        sub_acc[sbstuff[4]] = sbstuff[3]\n",
    "\n",
    "planned_visits = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/planned_visits/OMRF_Planned_Visits.txt\"\n",
    "pv_acc = defaultdict(dict)\n",
    "\n",
    "with open(planned_visits, \"r\") as pvi:\n",
    "    pvifl = pvi.readline()\n",
    "    for pviline in pvi:\n",
    "        pviline = pviline.strip()\n",
    "        pvistuff = pviline.split(\"\\t\")\n",
    "        \n",
    "        pv_acc[pvistuff[7]][pvistuff[1]] = pvistuff[0]   \n",
    "\n",
    "empty = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_days = defaultdict(dict)\n",
    "with open(workingfile) as alldata:\n",
    "    pffle = alldata.readline()\n",
    "    for lines in alldata:\n",
    "        stuff = lines.split(\"\\t\")\n",
    "        pv_days[stuff[0]][stuff[1]] = {\n",
    "            pv_acc[stuff[0]][\"1\"] : stuff[9] ,\n",
    "            pv_acc[stuff[0]][\"2\"] : stuff[19] ,\n",
    "            pv_acc[stuff[0]][\"3\"] : stuff[29] ,\n",
    "            pv_acc[stuff[0]][\"4\"] : stuff[40]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/experimentSamples.HAI.txt was generated and can now be populated\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### HAI ExpSample\n",
    "hai_data = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/workingfiles/HAI_rawdata.txt\"\n",
    "## HAI\n",
    "hai_t = bs.generatetemplate(\"hai\", template_dir)\n",
    "\n",
    "hai_prev = defaultdict(dict)\n",
    "hai_prevrk = defaultdict(dict)\n",
    "hai_pstv = defaultdict(dict)\n",
    "hai_pstvrk = defaultdict(dict)\n",
    "\n",
    "flustrains = {\n",
    "    \"SDY196\" : \"A/California/7/2004\",\n",
    "    \"SDY197\" : \"A/Wisconsin/67/2005\",\n",
    "    \"SDY198\" : \"A/Solomon Islands/3/2006\",\n",
    "    \"SDY199\" : \"A/Uruguay/716/2007\",\n",
    "    \"SDY200\" : \"A/Uruguay/716/2007\",\n",
    "    \"SDY201\" : \"A/Perth/16/2009\"\n",
    "}\n",
    "\n",
    "with open(hai_data, \"r\") as haid:\n",
    "    haidfl = haid.readline()\n",
    "    \n",
    "    for haidline in haid:\n",
    "        if not haidline.endswith(\"A\"):\n",
    "            haidline = haidline.strip()\n",
    "            haiddata = haidline.split(\"\\t\")\n",
    "            hai_prev[haiddata[0]][haiddata[1]] = haiddata[2]\n",
    "            hai_prevrk[haiddata[0]][haiddata[1]] = haiddata[3]\n",
    "            hai_pstv[haiddata[0]][haiddata[1]] = haiddata[4]\n",
    "            hai_pstvrk[haiddata[0]][haiddata[1]] = haiddata[5]\n",
    "\n",
    "with open(hai_t, \"a\") as hai:\n",
    "    for studies in sdy_yr:\n",
    "        extension = \".\".join([studies, \"txt\"])\n",
    "        addfile = \"_\".join([\"omrf_ranks\", extension])\n",
    "        for subacc in hai_prev[studies]:\n",
    "            prexpmtsplID = \"_\".join([sub_acc[subacc], sdy_yr[studies], studies, \"HAI_prevac\"])\n",
    "            prebiosplID = \"_\".join([sub_acc[subacc], sdy_yr[studies], studies, \"serum_prevac\"])\n",
    "            pstxpmtsplID = \"_\".join([sub_acc[subacc], sdy_yr[studies], studies, \"HAI_postvac\"])\n",
    "            pstbiosplID = \"_\".join([sub_acc[subacc], sdy_yr[studies], studies, \"serum_postvac\"])\n",
    "            prexpID = \"_\".join([\"HAI_prevac\", studies])\n",
    "            pstxpID = \"_\".join([\"HAI_postvac\", studies])\n",
    "            rk_prevax = \" : \".join([\"prevac_HAI_yr_rk\", hai_prevrk[studies][subacc]]) \n",
    "            rk_postvax =\" : \".join([\"postvac_HAI_yr_rk\", hai_pstvrk[studies][subacc]])\n",
    "            prename = \"_\".join([\"HAI_prevac\", studies])\n",
    "            postname = \"_\".join([\"HAI_postvac\", studies])\n",
    "            hai.write(\"\\t\".join([empty, prexpmtsplID, prebiosplID, prexpID, empty, empty, empty, empty,\n",
    "                                addfile, studies, \"PTL7329;PTL6909\", subacc, pv_acc[studies][\"1\"], \"Serum\",\n",
    "                                empty, empty, empty, \"0\", \"Days\", \"Time of initial vaccine administration\", \n",
    "                                empty, prename, empty, \"Neutralizing_Antibody_Titer\", \n",
    "                                \"Hemagglutination_Inhibition\", empty, flustrains[studies], \n",
    "                                hai_prev[studies][subacc], rk_prevax]) + \"\\n\") \n",
    "            hai.write(\"\\t\".join([empty, pstxpmtsplID, pstbiosplID, pstxpID, empty, empty, empty, empty,\n",
    "                                addfile, studies, \"PTL7329;PTL6909\", subacc, \"PlaceHolder_PV\", \"Serum\",\n",
    "                                empty, empty, empty, \"PlaceHolderVisitDay\", \"Days\", \n",
    "                                \"Time of initial vaccine administration\", empty, postname, empty,\n",
    "                                \"Neutralizing_Antibody_Titer\", \"Hemagglutination_Inhibition\", empty,\n",
    "                                flustrains[studies], hai_pstv[studies][subacc], rk_postvax]) + \"\\n\") \n",
    "            \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/interventions.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "## Interventions\n",
    "inter_t = bs.generatetemplate(\"inter\", template_dir)\n",
    "\n",
    "inter_data = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/interventions_rawdata.txt\"\n",
    "counter_iv = {\n",
    "    \"SDY196\" : 0,\n",
    "    \"SDY197\" : 0,\n",
    "    \"SDY198\" : 0,\n",
    "    \"SDY199\" : 0,\n",
    "    \"SDY200\" : 0,\n",
    "    \"SDY201\" : 0\n",
    "}\n",
    "inters = defaultdict(dict)\n",
    "with open(inter_data, \"r\") as it:\n",
    "    itfl = it.readline()\n",
    "    itfl = itfl.strip()\n",
    "    headers = itfl.split(\"\\t\")\n",
    "    \n",
    "    for itlines in it:\n",
    "        if re.search(\"yes\", itlines):\n",
    "            itlines = itlines.strip()\n",
    "            itstuff = itlines.split(\"\\t\")\n",
    "            inters[itstuff[0]][itstuff[1]] = []\n",
    "            for i in range(len(itstuff)):\n",
    "                if itstuff[i] == \"yes\":\n",
    "                    inters[itstuff[0]][itstuff[1]].append(headers[i])\n",
    "\n",
    "sub_med = defaultdict(dict)\n",
    "pred = defaultdict(dict)\n",
    "pred1 = \"prednisone_10\"\n",
    "pred2 = \"prednisone_10_30\"\n",
    "pred3 = \"prednisone_30\"\n",
    "\n",
    "for truc in inters:\n",
    "    for bid in inters[truc]:\n",
    "        medocs = []\n",
    "        for chou in inters[truc][bid]:\n",
    "            if chou.startswith(\"Predn\"):\n",
    "                medocs.append(\"Prednisone\")\n",
    "                if pred1 in inters[truc][bid]:\n",
    "                    if pred2 in inters[truc][bid]:\n",
    "                        pred[truc][bid] = \"less than 30mg\"\n",
    "                    else:\n",
    "                        pred[truc][bid] = \"less than 10mg\"\n",
    "                elif pred2 in inters[truc][bid]:\n",
    "                    if pred3 in inters[truc][bid]:\n",
    "                        pred[truc][bid] = \"over 30mg or less\"\n",
    "                    else:\n",
    "                        pred[truc][bid] = \"between 10mg and 30mg\"\n",
    "                elif pred3 in inters[truc][bid]:\n",
    "                    pred[truc][bid] = \"over 30mg\"\n",
    "                else:\n",
    "                    pred[truc][bid] = \"UNK\"\n",
    "            elif not chou.startswith(\"pre\"):\n",
    "                medocs.append(chou)\n",
    "        sub_med[truc][bid] = list(medocs)\n",
    "        \n",
    "                    \n",
    "with open(inter_t, \"a\") as iv:\n",
    "    for sdies in counter_iv:\n",
    "        for sujets in sub_med[sdies]:\n",
    "            for meds in sub_med[sdies][sujets]:\n",
    "                counter_iv[sdies] += 1\n",
    "                ivID = \"_\".join([\"OMRF\", sdies, str(counter_iv[sdies]).zfill(3)])\n",
    "                dose = \"UNK\"\n",
    "                if meds.startswith(\"Pred\"):\n",
    "                    dose = pred[sdies][sujets]\n",
    "                ivname = meds\n",
    "                ivcname = meds\n",
    "                if meds.startswith(\"Az\"):\n",
    "                    ivname = \"Imuran\"\n",
    "                    ivcname = \"Azathioprine\"\n",
    "                if meds.startswith(\"Hydr\"):\n",
    "                    ivname = \"Plaquenil\"\n",
    "                    ivcname = \"Hydroxychloroquine\"\n",
    "                if meds.startswith(\"M\"):\n",
    "                    ivname = \"Methotrexate\"\n",
    "                    ivcname = ivname\n",
    "                iv.write(\"\\t\".join([empty, ivID, sujets, sdies, ivname, ivcname, \"Concomitant Medication\",\n",
    "                                   dose, \"0\"]) + \"\\n\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY196.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY197.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY198.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY199.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY200.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.medH.SDY201.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY196.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY197.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY198.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY199.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY200.txt was generated and can now be populated\n",
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/assessments.sle.SDY201.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "## assessments\n",
    "assessments_t1 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY196.txt\")\n",
    "assessments_t2 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY197.txt\")\n",
    "assessments_t3 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY198.txt\")\n",
    "assessments_t4 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY199.txt\")\n",
    "assessments_t5 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY200.txt\")\n",
    "assessments_t6 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.medH.SDY201.txt\")\n",
    "assessments_s1 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY196.txt\")\n",
    "assessments_s2 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY197.txt\")\n",
    "assessments_s3 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY198.txt\")\n",
    "assessments_s4 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY199.txt\")\n",
    "assessments_s5 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY200.txt\")\n",
    "assessments_s6 = bs.generatetemplate(\"assmts\", template_dir, \"assessments.sle.SDY201.txt\")\n",
    "\n",
    "assmt_files = {\n",
    "    \"SDY196\" : [assessments_t1, assessments_s1],\n",
    "    \"SDY197\" : [assessments_t2, assessments_s2],\n",
    "    \"SDY198\" : [assessments_t3, assessments_s3],\n",
    "    \"SDY199\" : [assessments_t4, assessments_s4],\n",
    "    \"SDY200\" : [assessments_t5, assessments_s5],\n",
    "    \"SDY201\" : [assessments_t6, assessments_s6]\n",
    "}\n",
    "counter_as = {\n",
    "    \"SDY196\" : 0,\n",
    "    \"SDY197\" : 0,\n",
    "    \"SDY198\" : 0,\n",
    "    \"SDY199\" : 0,\n",
    "    \"SDY200\" : 0,\n",
    "    \"SDY201\" : 0\n",
    "}\n",
    "\n",
    "sub_age = {}\n",
    "with open(subject_dir, \"r\") as sb:\n",
    "    sbfl = sb.readline()\n",
    "    for sblines in sb:\n",
    "        sblines = sblines.strip(\"\\n\")\n",
    "        sbstuff = sblines.split(\"\\t\")\n",
    "        \n",
    "        sub_age[sbstuff[4]] = sbstuff[6]\n",
    "        \n",
    "# pv_acc[study][order number]= planned_visit_acc\n",
    "assess_medH = defaultdict(dict)\n",
    "assess_sle = defaultdict(dict)\n",
    "assess_dates = defaultdict(dict)\n",
    "assess_names = []\n",
    "assessments = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/assessments_rawdata.txt\"\n",
    "with open(assessments, \"r\") as ast:\n",
    "    astfl = ast.readline()\n",
    "    astfl = astfl.strip()\n",
    "    asstnames = astfl.split(\"\\t\")\n",
    "    assess_names = list(asstnames[5:33])\n",
    "    \n",
    "    for astlines in ast:\n",
    "        astlines = astlines.strip()\n",
    "        aststuff = astlines.split(\"\\t\")\n",
    "        \n",
    "        assess_medH[aststuff[0]][aststuff[1]] = list(aststuff[5:33])\n",
    "\n",
    "        assess_sle[aststuff[0]][aststuff[1]] = {\n",
    "            \"PGA\" : {\"1\": aststuff[33], \"3\": aststuff[34], \"4\": aststuff[35]},\n",
    "            \"PGA2\" : {\"1\": aststuff[36], \"3\": aststuff[37], \"4\": aststuff[38]},\n",
    "            \"SLEDAI\" : {\"1\": aststuff[39], \"3\": aststuff[40], \"4\": aststuff[41]},\n",
    "            \"SLAM\" : {\"1\": aststuff[44], \"3\": aststuff[45], \"4\": aststuff[46]},\n",
    "            \"SLICC\" : {\"1\": aststuff[47], \"4\": aststuff[48]},\n",
    "            \"Flare\" : {\"3\": aststuff[42], \"4\": aststuff[43]}\n",
    "        }\n",
    "\n",
    "        assess_dates[aststuff[0]][aststuff[1]] = {\"1\" : \"0\", \"3\" : aststuff[3], \"4\" : aststuff[4]}\n",
    "                \n",
    "for study in assmt_files:\n",
    "    with open(assmt_files[study][0], \"a\") as medH, open(assmt_files[study][1], \"a\") as sle:\n",
    "        for subject in assess_medH[study]:\n",
    "            medhist = []\n",
    "            for j in range(0, len(assess_medH[study][subject])):\n",
    "                counter_as[study] += 1\n",
    "                assess_compID = \"_\".join([\"OMRF\", study, assess_names[j], str(counter_as[study]).zfill(4)])\n",
    "                new_medh = \"\\t\".join([assess_compID, pv_acc[study][\"1\"], assess_names[j], \n",
    "                                      assess_dates[study][subject][\"1\"], empty, sub_age[subject], \"Years\",\n",
    "                                      empty, empty, empty, assess_medH[study][subject][j], empty, empty,\n",
    "                                      empty, empty, empty, empty])\n",
    "                medhist.append(new_medh)\n",
    "            asst_panel = \"_\".join([\"OMRF\", study, \"medical_history\"])\n",
    "            medH.write(\"\\t\".join([empty, subject, asst_panel, study, \"Medical History\", \"Medical History\",\n",
    "                                  empty, empty, empty, empty, empty]))\n",
    "            medH.write(\"\\t\".join(medhist) + \"\\n\")\n",
    "            \n",
    "            slescores = []\n",
    "            for scales in assess_sle[study][subject]:\n",
    "                for visits in assess_sle[study][subject][scales]:\n",
    "                    if not assess_sle[study][subject][scales][visits].startswith(\"N\"):\n",
    "                        counter_as[study] += 1\n",
    "                        assess_comp = \"_\".join([\"OMRF\", study, scales, str(counter_as[study]).zfill(4)])\n",
    "                        new_score = \"\\t\".join([assess_comp, pv_acc[study][visits], scales, \n",
    "                                          assess_dates[study][subject][visits], empty, sub_age[subject], \"Years\",\n",
    "                                          empty, empty, empty, assess_sle[study][subject][scales][visits], empty, \n",
    "                                          empty, empty, empty, empty, empty])\n",
    "                        slescores.append(new_score)\n",
    "            if slescores:\n",
    "                slepanel = \"_\".join([\"OMRF\", study, \"SLE_panel\"])\n",
    "                sle.write(\"\\t\".join([empty, subject, asst_panel, study, \"SLE Panel\", \"Other\",\n",
    "                                      empty, empty, empty, empty, empty]))\n",
    "\n",
    "                sle.write(\"\\t\".join(slescores) + \"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/experimentSamples.Other.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "wblots_t = bs.generatetemplate(\"other\", template_dir)\n",
    "wb_data = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/WB_rawdata.txt\"\n",
    "\n",
    "wb_path = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/wb\"\n",
    "wb_files = {\n",
    "    \"SDY196\" : \"omrf_WB_project4B_SDY196.txt\",\n",
    "    \"SDY197\" : \"omrf_WB_project4B_SDY197.txt\",\n",
    "    \"SDY198\" : \"omrf_WB_project4B_SDY198.txt\",\n",
    "    \"SDY199\" : \"omrf_WB_project4B_SDY199.txt\"\n",
    "}\n",
    "\n",
    "wbheaders = None\n",
    "wbinfo = defaultdict(dict)\n",
    "with open(wb_data, \"r\") as wbd:\n",
    "    wbheaders = wbd.readline()\n",
    "    \n",
    "    for wbdline in wbd:\n",
    "        wbdline = wbdline.strip()\n",
    "        wbdstuff = wbdline.split(\"\\t\")\n",
    "        if len(set(wbdstuff)) > 3:\n",
    "            wbinfo[wbdstuff[0]][wbdstuff[1]] = wbdline\n",
    "\n",
    "with open(wblots_t, \"a\") as wb:\n",
    "    for sdy in wb_files:\n",
    "        wbresultfile = os.path.join(wb_path, wb_files[sdy])\n",
    "        with open(wbresultfile, \"w\") as wbr:\n",
    "            wbr.write(wbheaders)\n",
    "\n",
    "            for eachsub in wbinfo[sdy]:\n",
    "                wbr.write(wbinfo[sdy][eachsub] + \"\\n\")\n",
    "                wbxpmtsplID = \"_\".join([sub_acc[eachsub], sdy_yr[sdy], sdy, \"Project4B\"])\n",
    "                wbbiosplID = \"_\".join([sub_acc[eachsub], sdy_yr[sdy], sdy, \"proteins\"])\n",
    "                wbxpID = \"_\".join([\"WesternBlot\", sdy])\n",
    "                \n",
    "                wb.write(\"\\t\".join([empty, wbxpmtsplID, wbbiosplID, wbxpID, empty, empty, wb_files[sdy],\n",
    "                                   empty, empty, empty, sdy, \"PTL5866\", eachsub, empty, \"Not_Specified\",\n",
    "                                   empty, empty, empty, empty, empty, empty, empty, wbxpID, empty, \n",
    "                                   \"Protein_Quantification\", \"Western_Blot\"]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/labTests.Project2.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "labtests_t = bs.generatetemplate(\"ltests\", template_dir, \"labTests.Project2.txt\")\n",
    "labtests_data = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/ELISA_rawdata_project2.txt\"\n",
    "sdtm = \"/home/cthomas/Desktop/cris/projects/BDD2123/clinical.lk_lab_test_name.txt\"\n",
    "\n",
    "counter_lt = {\n",
    "    \"SDY196\" : 0,\n",
    "    \"SDY197\" : 0,\n",
    "    \"SDY198\" : 0,\n",
    "    \"SDY199\" : 0,\n",
    "    \"SDY200\" : 0,\n",
    "    \"SDY201\" : 0\n",
    "}\n",
    "\n",
    "sdtm_term = {}\n",
    "with open(sdtm, \"r\") as sdtmt:\n",
    "    for sdtmlines in sdtmt:\n",
    "        sdtmstuff = sdtmlines.split(\"\\t\")\n",
    "        sdtm_term[sdtmstuff[9]] = sdtmstuff[0]\n",
    "\n",
    "labtestcodes = {\n",
    "    \"dsDNA_cri\" : \"C74913\",\n",
    "    \"Ro_0_13\" : \"C92236\",\n",
    "    \"La_0_18\" : \"C92237\",\n",
    "    \"sm_nRNP_0_15\" : \"C120658\",\n",
    "    \"sm_0_2\" : \"C92281\",\n",
    "    \"Ribo_P_0_122\" : \"C120659\",\n",
    "    \"ANA\" : \"C74916\",\n",
    "    \"aPL_0_3\" : \"C102258\",\n",
    "    \"total_IgG\" : \"C81971\",\n",
    "    \"dsDNA_IU_117\" : \"C74913\"\n",
    "}\n",
    "        \n",
    "labtestresults = defaultdict(dict)\n",
    "tmplabtestnames = []\n",
    "\n",
    "with open(labtests_data, \"r\") as lbd:\n",
    "    lbdfl = lbd.readline()\n",
    "    lbdfl = lbdfl.strip()\n",
    "    tmplabtestnames = lbdfl.split(\"\\t\")\n",
    "    \n",
    "    for lblines in lbd:\n",
    "        lblines = lblines.strip()\n",
    "        lbstuff = lblines.split(\"\\t\")\n",
    "\n",
    "        labtestresults[lbstuff[0]][lbstuff[1]] = list(lbstuff)\n",
    "\n",
    "labtestnames = []\n",
    "for allnames in tmplabtestnames:\n",
    "    tmpnm = allnames.split(\"_\")\n",
    "    nwnm = \"_\".join(tmpnm[1:])\n",
    "    labtestnames.append(nwnm)\n",
    "    \n",
    "with open(labtests_t, \"a\") as lb:\n",
    "    for etude in labtestresults:\n",
    "        for sjt in labtestresults[etude]:\n",
    "            pv_res = defaultdict(list)\n",
    "            unit = \"boolean\"\n",
    "            for k in range(3, 12):\n",
    "                counter_lt[etude] += 1\n",
    "                if not labtestresults[etude][sjt][k].endswith(\"A\"):\n",
    "                    if labtestnames[k].endswith(\"G\"):\n",
    "                        unit = \"mg/ml\"\n",
    "                    lbtestname = \"_\".join([labtestnames[k], etude, str(counter_lt[etude]).zfill(4)])\n",
    "                    lbres1 = \"\\t\".join([lbtestname, sdtm_term[labtestcodes[labtestnames[k]]], \n",
    "                                      labtestresults[etude][sjt][k], unit])\n",
    "                    pv_res[\"1\"].append(lbres1)\n",
    "            unit = \"boolean\"\n",
    "\n",
    "            for l in range(13, 22):\n",
    "                if not labtestresults[etude][sjt][l].endswith(\"A\"):\n",
    "                    counter_lt[etude] += 1\n",
    "                    if labtestnames[l].endswith(\"G\"):\n",
    "                        unit = \"mg/ml\"\n",
    "                    lbtestnm = \"_\".join([labtestnames[l], etude, str(counter_lt[etude]).zfill(4)])\n",
    "                    lbres2 = \"\\t\".join([lbtestnm, sdtm_term[labtestcodes[labtestnames[l]]], \n",
    "                                      labtestresults[etude][sjt][l], unit])\n",
    "                    pv_res[\"2\"].append(lbres2)\n",
    "            unit = \"boolean\"\n",
    "                \n",
    "            for m in range(23, 33):\n",
    "                if not labtestresults[etude][sjt][m].endswith(\"A\"):\n",
    "                    counter_lt[etude] += 1\n",
    "                    if labtestnames[m].endswith(\"G\"):\n",
    "                        unit = \"mg/ml\"\n",
    "                    if not labtestnames[m].endswith(\"type\"):\n",
    "                        ltestname = \"_\".join([labtestnames[m], etude, str(counter_lt[etude]).zfill(4)])\n",
    "                        lbres3 = \"\\t\".join([ltestname, sdtm_term[labtestcodes[labtestnames[m]]], \n",
    "                                          labtestresults[etude][sjt][m], unit])\n",
    "                        pv_res[\"3\"].append(lbres3)\n",
    "            unit = \"boolean\"\n",
    "    \n",
    "            for n in range(13, 22):\n",
    "                if not labtestresults[etude][sjt][m].endswith(\"A\"):\n",
    "                    counter_lt[etude] += 1\n",
    "                    if labtestnames[n].endswith(\"G\"):\n",
    "                        unit = \"mg/ml\"\n",
    "                    ltestnm = \"_\".join([labtestnames[n], etude, str(counter_lt[etude]).zfill(4)])\n",
    "                    lbres4 = \"\\t\".join([ltestnm, sdtm_term[labtestcodes[labtestnames[n]]], \n",
    "                                      labtestresults[etude][sjt][n], unit])\n",
    "                    pv_res[\"4\"].append(lbres4)\n",
    "            \n",
    "            drawdays = {\n",
    "                \"1\" : labtestresults[etude][sjt][2], \n",
    "                \"2\" : labtestresults[etude][sjt][12],\n",
    "                \"3\" : labtestresults[etude][sjt][22],\n",
    "                \"4\" : labtestresults[etude][sjt][33]\n",
    "            }\n",
    "            for eachvisit in pv_res:\n",
    "                biosampleID = \"_\".join([sub_acc[sjt], sdy_yr[etude], etude, \"draw\", eachvisit])\n",
    "                labpanelID = \"_\".join([etude, \"Project2\", \"draw\", eachvisit])\n",
    "                lbresult = \"\\t\".join(pv_res[eachvisit])\n",
    "                lb.write(\"\\t\".join([empty, biosampleID, labpanelID, etude, empty, sjt, pv_acc[etude][eachvisit],\n",
    "                                   \"Not_Specified\", empty, empty, empty, drawdays[eachvisit], \"Days\",\n",
    "                                   \"Time of initial vaccine administration\", empty, \"Immunology Test\",\n",
    "                                   empty, lbresult]) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/experimentSamples.ELISPOT.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "## EliSPOT\n",
    "elispot_t = bs.generatetemplate(\"elispot\", template_dir)\n",
    "elispot_data = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/ELISPOT_rawdata.txt\"\n",
    "\n",
    "elispot_res = defaultdict(dict)\n",
    "\n",
    "with open(elispot_data, \"r\") as elid:\n",
    "    elidfl = elid.readline()\n",
    "    \n",
    "    for elilines in elid:\n",
    "        elilines = elilines.strip()\n",
    "        elistuff = elilines.split(\"\\t\")\n",
    "        tmpeli = {\n",
    "            \"PHA\" : {\n",
    "                \"prevac\": {\"spots\" : elistuff[2], \"rank\" : elistuff[6] },\n",
    "                \"postvac\" : {\"spots\" : elistuff[4] , \"rank\" : elistuff[8] }\n",
    "            },\n",
    "            \"vacc\" : {\n",
    "                \"prevac\": {\"spots\" : elistuff[3] , \"rank\" : elistuff[7] },\n",
    "                \"postvac\" : {\"spots\" : elistuff[5] , \"rank\" : elistuff[9] }\n",
    "            }\n",
    "        }\n",
    "        elispot_res[elistuff[0]][elistuff[1]] = tmpeli\n",
    "        \n",
    "elispot_pv = {}\n",
    "\n",
    "with open(elispot_t, \"a\") as eli:\n",
    "    for stdy in elispot_res:\n",
    "        elispot_pv[stdy] = {\n",
    "            \"prevac\" : pv_acc[stdy][\"1\"],\n",
    "            \"postvac\" : \"PLACEHOLDER_POSTVAC_VISIT\"\n",
    "        }\n",
    "        for subID in elispot_res[stdy]:\n",
    "            pv_days[stdy][subID][elispot_pv[stdy][\"postvac\"]] = \"PlaceHolderPVDay\"\n",
    "            for treatment in elispot_res[stdy][subID]:\n",
    "                for time in elispot_res[stdy][subID][treatment]:\n",
    "                    if not elispot_res[stdy][subID][treatment][time][\"spots\"].endswith(\"A\"):\n",
    "                        eliesID = \"_\".join([sub_acc[subID], sdy_yr[stdy], stdy, \"ELISPOT\", treatment, time ])\n",
    "                        elibiospID = \"_\".join([sub_acc[subID], sdy_yr[stdy], stdy, \"serum\", treatment, time])\n",
    "                        elixpID = \"_\".join([\"ELISPOT\", treatment, time, stdy])\n",
    "                        treatmtID = \"_\".join([stdy, treatment, time])\n",
    "                        elirk = \"_\".join([\"ES\", time, treatment, \"spots_yr_rk\"])\n",
    "                        elirank = \":\".join([elirk, elispot_res[stdy][subID][treatment][time][\"rank\"]])\n",
    "                        eli.write(\"\\t\".join([empty, eliesID, elibiospID, elixpID, empty, treatmtID, empty,\n",
    "                                            empty, empty, stdy, empty, subID, elispot_pv[stdy][time], \n",
    "                                            \"Not_Specified\", empty, empty, empty, \n",
    "                                             pv_days[stdy][subID][elispot_pv[stdy][time]], \"Days\",\n",
    "                                            \"Time of initial vaccine administration\", empty, elixpID, empty,\n",
    "                                            \"Cellular_Activity\", \"ELISPOT\", empty, \"IFNG\", \n",
    "                                            elispot_res[stdy][subID][treatment][time][\"spots\"], \"100000\",\n",
    "                                             \"SFUs\", elirank]) + \"\\n\")\n",
    " \n",
    "                                       \n",
    "                                       \n",
    "                                       \n",
    "                                       \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a valid abbreviation to generate a template\n",
      "/home/cthomas/Desktop/cris/projects/BDD2098/files/templates/experimentSamples.Other.Project1.txt was generated and can now be populated\n"
     ]
    }
   ],
   "source": [
    "project1_t = bs.generatetemplate(\"other\", template_dir, \"experimentSamples.Other.Project1.txt\")\n",
    "elisa_data1 = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/ELISA_rawdata_project1.txt\"\n",
    "\n",
    "\n",
    "elisa_path = \"/home/cthomas/Desktop/cris/projects/BDD2098/files/project1\"\n",
    "elisa_files = {\n",
    "    \"SDY196\" : \"omrf_project1_SDY196.txt\",\n",
    "    \"SDY197\" : \"omrf_project1_SDY197.txt\",\n",
    "    \"SDY198\" : \"omrf_project1_SDY198.txt\",\n",
    "    \"SDY199\" : \"omrf_project1_SDY199.txt\",\n",
    "    \"SDY200\" : \"omrf_project1_SDY200.txt\",\n",
    "    \"SDY201\" : \"omrf_project1_SDY201.txt\"\n",
    "}\n",
    "\n",
    "airinfo = defaultdict(dict)\n",
    "airheaders = \"\"\n",
    "with open(elisa_data1, \"r\") as aird:\n",
    "    airheaders = aird.readline()\n",
    "    \n",
    "    for airline in aird:\n",
    "        airline = airline.strip()\n",
    "        airstuff = airline.split(\"\\t\")\n",
    "        if len(set(airstuff)) > 3:\n",
    "            airinfo[airstuff[0]][airstuff[1]] = airline\n",
    "\n",
    "with open(project1_t, \"a\") as pjt:\n",
    "    for eachstudy in elisa_files:\n",
    "        airresultfile = os.path.join(elisa_path, elisa_files[eachstudy])\n",
    "        with open(airresultfile, \"w\") as air:\n",
    "            air.write(airheaders)\n",
    "\n",
    "            for eachsubject in airinfo[eachstudy]:\n",
    "                air.write(airinfo[eachstudy][eachsubject] + \"\\n\")\n",
    "                airxpmtsplID = \"_\".join([sub_acc[eachsubject], sdy_yr[eachstudy], eachstudy, \"Project1\"])\n",
    "                airbiosplID = \"_\".join([sub_acc[eachsubject], sdy_yr[eachstudy], eachstudy, \"serum_Project1\"])\n",
    "                airxpID = \"_\".join([\"Project1\", eachstudy])\n",
    "                airaddfile = \"\".join([\"omrf_ranks_\", eachstudy, \".txt\"])\n",
    "                pjt.write(\"\\t\".join([empty, airxpmtsplID, airbiosplID, airxpID, empty, empty, elisa_files[sdy],\n",
    "                                   empty, empty, airaddfile, eachstudy, \"PTL5866\", eachsubject, empty, \"Not_Specified\",\n",
    "                                   empty, empty, empty, empty, empty, empty, empty, airxpID, empty, \n",
    "                                   \"Other\", \"ELISA\"]) + \"\\n\")\n",
    "\n",
    "## created additional result files for the ranks -- omrf_ranks_SDY196.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Other test -- labtests\n",
    "### ELISA\n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
